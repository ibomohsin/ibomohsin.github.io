---
layout: default
---

## About me

I'm passionate about advancing ethical and inclusive AI, with a particular focus on developing robust multimodal systems, understanding neural network behavior, and addressing fairness and cultural diversity in machine learning models. I am also interested in the application of mathematical tools, such as fractals, statistical learning theory & information theory, to understand the capabilities and limitations of deep neural networks. Prior to joining Google Deepmind in Z\"urich, I founded and led the Advanced Analytics team at Saudi Aramco, managed the company’s Enterprise Analytics program, and was a technical lead at its digital transformation program. 


## Education

- **Ph.D.** in Computer Science at [KAUST](https://www.kaust.edu.sa/) (2012 - 2017), _GPA: 4.0 / 4.0_.
  - Thesis Title: _Learning via Query Synthesis_, Committee: X. Zhang, X. Gao, D. Keyes (KAUST), and W. Wang (UCLA).
- **M.S.** in Electrical Engineering at [Stanford University](https://www.stanford.edu/) (2009 - 2011), _GPA: 4.15 / 4.0_. 
- **B.S.** in Computer Engineering at [University of Nebraska, Lincoln](https://www.unl.edu/) (2000 - 2005),  _GPA: 3.98 / 4.0_.
  - _Highest Distinction_, _Superior Scholarship Award_, _Minor in Economics_.

## Selected Activities
- Area Chair @ [NeurIPS](https://nips.cc/) and [ICML](https://icml.cc/).
- Program committee member at [ICLR](https://iclr.cc/), [AAAI](https://aaai.org/Conferences/AAAI-22/), [CVPR](https://cvpr2023.thecvf.com/) and [ECCV](https://eccv.ecva.net/).
- [Featured](https://lnkd.in/eGPzHwi7) at the Saudi national TV on March, 2024. The episode explored my career.
- Member of the [S20 Task Force](https://s20saudiarabia.org.sa/theme.html) (Digital Revolution) that contributed to an executive report for the G20 summit, 2020.
- Chair of AI track of the 2019 [Arab-American Frontiers Symposium](https://www.nationalacademies.org/our-work/arab-american-frontiers-of-science-engineering-and-medicine), 2019.

## Books
Ibrahim Alabdulmohsin, *Summability Calculus: A Comprehensive Theory of Fractional Finite Sums*, Springer, 2018.

## Recent Preprints
- Xi Chen, Xiao Wang, Lucas Beyer, Alexander Kolesnikov, Jialin Wu, Paul Voigtlaender, Basil Mustafa, Sebastian Goodman, Ibrahim Alabdulmohsin, Piotr Padlewski, et al:
"*PaLI-3 Vision Language Models: Smaller, Faster, Stronger.*" ArXiv: abs/2310.09199 (2023)

## Recent Publications
- Ibrahim Alabdulmohsin, Vinh Q. Tran, and Mostafa Dehghani: "*Fractal Patterns May Illuminate the Success of Next-Token Prediction.*" **NeurIPS**, 2024.
- Bo Wan, Michael Tschannen, Yongqin Xian, Filip Pavetic, Ibrahim Alabdulmohsin, Xiao Wang, André Susano Pinto, Andreas Steiner, Lucas Beyer, Xiaohua Zhai: "*LocCa: Visual Pretraining with Location-aware Captioners*" **NeurIPS**, 2024.
- Angéline Pouget, Lucas Beyer, Emanuele Bugliarello, Xiao Wang, Andreas Peter Steiner, Xiaohua Zhai, Ibrahim Alabdulmohsin: "*No Filter: Cultural and Socioeconomic Diversity in Contrastive Vision-Language Models*" **NeurIPS**, 2024.
- Ibrahim Alabdulmohsin, Xiao Wang, Andreas Peter Steiner, Priya Goyal, Alexander D'Amour, Xiaohua Zhai: "*CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?*" **ICLR**, 2024.
-   Xi Chen, Josip Djolonga, Piotr Padlewski, Basil Mustafa, Soravit Changpinyo, Jialin Wu, Carlos Riquelme Ruiz, Sebastian Goodman, Xiao Wang, Yi Tay, Siamak Shakeri, Mostafa Dehghani, Daniel Salz, Mario Lucic, Michael Tschannen, Arsha Nagrani, Hexiang Hu, Mandar Joshi, Bo Pang, Ceslee Montgomery, Paulina Pietrzyk, Marvin Ritter, A. J. Piergiovanni, Matthias Minderer, Filip Pavetic, Austin Waters, Gang Li, Ibrahim Alabdulmohsin, Lucas Beyer, et al:
"*PaLI-X: On Scaling up a Multilingual Vision and Language Model.*" **CVPR**, 2024.
- Ibrahim Alabdulmohsin, Xiaohua Zhai, Alexander Kolesnikov, Lucas Beyer:
"*Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design.*" **NeurIPS**, 2023.
- Mostafa Dehghani, Basil Mustafa, Josip Djolonga, Jonathan Heek, Matthias Minderer, Mathilde Caron, Andreas Steiner, Joan Puigcerver, Robert Geirhos, Ibrahim Alabdulmohsin, Avital Oliver, Piotr Padlewski, Alexey A. Gritsenko, Mario Lucic, Neil Houlsby: "*Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution.*"
 **NeurIPS**, 2023.
- Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, Rodolphe Jenatton, Lucas Beyer, Michael Tschannen, et al:
"*Scaling Vision Transformers to 22 Billion Parameters.*" **ICML**, 2023.
- Lucas Beyer, Pavel Izmailov, Alexander Kolesnikov, Mathilde Caron, Simon Kornblith, Xiaohua Zhai, Matthias Minderer, Michael Tschannen, Ibrahim Alabdulmohsin, Filip Pavetic: "*FlexiViT: One Model for All Patch Sizes*," **CVPR**, 2023.
- Ibrahim Alabdulmohsin, Nicole Chiou, Alexander D'Amour, Arthur Gretton, Sanmi Koyejo, Matt J. Kusner, Stephen R. Pfohl, Olawale Salaudeen, Jessica Schrouff, Katherine Tsai: "*Adapting to Latent Subgroup Shifts via Concepts and Proxies*," **AISTATS**, 2023.
- Ibrahim Alabdulmohsin, Behnam Neyshabur, Xiaohua Zhai: "*Revisiting Neural Scaling Laws in Language and Vision*," **NeurIPS**, 2022.
- Ibrahim Alabdulmohsin, Jessica Schrouff, Oluwasanmi Koyejo: "*A Reduction to Binary Approach for Debiasing Multiclass Datasets*,"  **NeurIPS**, 2022.
- Jessica Schrouff, Natalie Harris, Oluwasanmi Koyejo, Ibrahim Alabdulmohsin, Eva Schnider, Krista Opsahl-Ong, Alexander Brown, Subhrajit Roy, Diana Mincu, Christina Chen, Awa Dieng, Yuan Liu, Vivek Natarajan, Alan Karthikesalingam, Katherine A. Heller, Silvia Chiappa, Alexander D'Amour: "*Maintaining fairness across distribution shift: do we have viable solutions for real-world applications?*", **NeurIPS**, 2022.
- Alexander Soen, Ibrahim Alabdulmohsin, Sanmi Koyejo, Yishay Mansour, Nyalleng Moorosi, Richard Nock, Ke Sun, Lexing Xie: 
"*Fair Wrapping for Black-box Predictions*," **NeurIPS**, 2022.

